# -*- coding: utf-8 -*-
"""AI_Genius_Forge_24Hr_Hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vpDtylJAXW5bPSuaL7Jk0j8tD9HzM_Ry

# Data Inspection and Understanding
"""

# from google.colab import drive
# drive.mount('/content/drive')

import sklearn
print("sklearn_Version",sklearn.__version__)
import pandas as pd
pd.set_option('display.max_columns', None)
import numpy as np

df = pd.read_csv("./dataset.csv")
(df.head())

# from google.colab import drive
# drive.mount('/content/drive')

# Display basic information about the dataset
print("INfo of the Dataset: \n")
(df.info())

# Check for missing values
print("\nChecking for missing values: \n")
print(df.isnull().sum())

# Check data types of variables
print("\nData types of all the Variables: \n")
df.dtypes

# Display summary statistics
print("\nDescription of dataset: \n")
df.describe()

"""# Data Preprocessing
Basically, We impute the misssing values here instead of removing them wholly since they are somewhat less compared to the whole dataset...


*   IMputing using mean or We can also impute using mode too...
*   


"""

from sklearn.impute import SimpleImputer

# SimpleImputer with strategy='mean'
imputer = SimpleImputer(strategy='median')

# Impute missing values in the 'Arrival Delay in Minutes' column
df['Arrival Delay in Minutes'] = imputer.fit_transform(df[['Arrival Delay in Minutes']])

"""IN the dataset, ONly for 'Arrival Delay in Minutes' column, We change into int from float datatype since there is no data loss and it is better if we have all int datatype for the model."""

df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].astype(int)

# New Changed datatype from float to int
df.info()

"""**Outlier Detection:**


*   From data description we found out that
*   List item


"""

categorical_features = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']
import matplotlib.pyplot as plt

# Remove the categorical features from the dataset
df_without_categorical = df.drop(columns=categorical_features)
# Iterate over each numerical predictor variable
for predictor in df_without_categorical:
    # Create scatter plot
    plt.figure(figsize=(8, 6))
    plt.scatter(df[predictor], df['satisfaction'], alpha=0.5)
    plt.title("Scatter plot of '{}' vs 'satisfaction'".format(predictor))
    plt.xlabel(predictor)
    plt.ylabel("Satisfaction")
    plt.grid(True)
    plt.show()

# df.describe(include = ['category'])

categorical_features = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']

# Iterate over each categorical feature
for feature in categorical_features:
    # Get the number of unique categories
    num_unique_categories = df[feature].nunique()
    print("Number of unique categories in '{}': {}".format(feature, num_unique_categories))
    print("Unique categories and their counts:")
    print(df[feature].value_counts())
    print()

"""**Nature of categorical variables (Nominal or ordinal):**


*   If your categorical variables are ordinal (i.e., they have a natural order or hierarchy), it might make sense to calculate correlations before label encoding, as label encoding may inadvertently introduce artificial ordinality.
*   However, if there is no inherent order among different categories, it would be treated as nominal.Then, there is no problem if u find the correlation after label encoding.


"""

# from scipy.stats import pointbiserialr
# df.head()
# # List of numerical predictor variables (assuming all numerical columns except the target variable)
# numerical_predictors = df.drop('satisfaction')

# # Iterate over each numerical predictor variable
# for predictor in numerical_predictors:
#     # Calculate Point-Biserial Correlation coefficient
#     correlation_coefficient, p_value = pointbiserialr(df[predictor], df['satisfaction'])

#     print("Predictor Variable:", predictor)
#     print("Point-Biserial Correlation coefficient:", correlation_coefficient)
#     print("P-value:", p_value)
#     print()

# # Calculate correlation matrix for numerical variables
# corr_matrix = df.corr()
# import matplotlib.pyplot as plt
# import seaborn as sns
# # Visualize the correlation matrix
# plt.figure(figsize=(20,20))
# sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
# plt.title('Correlation Matrix')
# plt.show()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
for col in categorical_features :
    df[col] = label_encoder.fit_transform(df[col])

print(df.head())

import seaborn as sns
import matplotlib.pyplot as plt

# Count plot for encoded 'Customer Type'
plt.figure(figsize=(8, 6))
sns.countplot(x='Customer Type', data=df)
plt.title("Count of Customer Type")
plt.xlabel("Customer Type")
plt.ylabel("Count")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Count plot for encoded 'Customer Type'
plt.figure(figsize=(8, 6))
sns.countplot(x='Checkin service', data=df)
plt.title("Count of Checkin service")
plt.xlabel("Checkin service")
plt.ylabel("Count")
plt.show()

import numpy as np
# List of categorical features to remove
categorical_features = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']

# Remove the categorical features from the dataset
df_without_categorical = df.drop(columns=categorical_features)

# Display the modified dataset
print(df_without_categorical.head())

# Calculate the first quartile (Q1)
Q1 = df.quantile(0.25)

# Calculate the third quartile (Q3)
Q3 = df.quantile(0.75)

# Calculate the interquartile range (IQR)
IQR = Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Find outliers for each numerical variable
outliers = {}
for col in df_without_categorical:
    outliers[col] = np.where((df[col] < lower_bound[col]) | (df[col] > upper_bound[col]))[0]

# Display outliers and count for each numerical variable
for col, idx in outliers.items():
    num_outliers = len(idx)
    print("Outliers for '{}': {} (Count: {})".format(col, idx, num_outliers))

from scipy.stats import mstats

# Define the variables with outliers
variables_with_outliers = ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']

# Apply Winsorization to handle outliers
for var in variables_with_outliers:
    # Winsorize the variable
    df[var] = mstats.winsorize(df[var], limits=[0.05, 0.05])

# Now, df contains the original variables with outliers replaced by Winsorized values

df.describe()

df.info()

# Count the number of null values in each column
null_counts = df.isnull().sum()

# Display the number of null values in each column
print("Number of null values in each column:")
print(null_counts)

# Verify if there are any null values after imputation
null_counts_after_imputation = df.isnull().sum()
print("Number of null values in each column after imputation:")
print(null_counts_after_imputation)

"""Here, the first two columns are not useful; so remove them"""

corr_matrix = df.corr()
# prompt: Exploratory data analysis on dataset.csv
import seaborn as sns
import matplotlib.pyplot as plt
# Visualize the correlation matrix
plt.figure(figsize=(25, 25))
sns.heatmap(corr_matrix, annot=True)
plt.show()

# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import mean_squared_error

# # Assuming your DataFrame is named df

# # Define the features (independent variables)
# X = df.drop(columns=['Unnamed: 0', 'id', 'satisfaction'])

# # Define the target variable (dependent variable)
# y = df['satisfaction']

# # Split the dataset into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Initialize the Linear Regression model
# model = LinearRegression()

# # Train the model on the training set
# model.fit(X_train, y_train)

# # Make predictions on the testing set
# y_pred = model.predict(X_test)

# # Evaluate the model
# mse = mean_squared_error(y_test, y_pred)
# print("Mean Squared Error:", mse)
# from sklearn.metrics import mean_absolute_error, r2_score

# # Calculate Mean Absolute Error (MAE)
# mae = mean_absolute_error(y_test, y_pred)
# print("Mean Absolute Error:", mae)

# # Calculate R-squared
# r_squared = r2_score(y_test, y_pred)
# print("R-squared:", r_squared)

# # Optionally, you can also calculate Root Mean Squared Error (RMSE)
# rmse = mean_squared_error(y_test, y_pred, squared=False)
# print("Root Mean Squared Error:", rmse)

# # Number of observations
# n = len(y_test)

# # Number of features
# p = X_test.shape[1]

# # Calculate R-squared
# r_squared = r2_score(y_test, y_pred)

# # Calculate Adjusted R-squared
# adjusted_r_squared = 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))
# print("Adjusted R-squared:", adjusted_r_squared)

# import matplotlib.pyplot as plt

# # Assuming your DataFrame is named df and you have already defined X and y

# # Iterate over each feature
# for feature in X.columns:
#     # Plot the feature against the target variable
#     plt.figure(figsize=(8, 6))
#     plt.scatter(df[feature], y, alpha=0.5)
#     plt.title("Relationship between {} and satisfaction".format(feature))
#     plt.xlabel(feature)
#     plt.ylabel("Satisfaction")
#     plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
# df = pd.read_csv('')  # Replace 'your_dataset.csv' with the path to your dataset

# Define the features (independent variables)
X = df.drop(columns=['Unnamed: 0', 'id', 'satisfaction'])

# Define the target variable (dependent variable)
y = df['satisfaction']


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train)

# Initialize the Random Forest Classifier model
rf_classifier = RandomForestClassifier(n_estimators=100)

# Train the model on the training set
rf_classifier.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

import joblib
joblib.dump(rf_classifier, 'RandomForestClassifier.joblib')

import pickle
with open('rf_classifier_model.pkl', 'wb') as file:
    pickle.dump(rf_classifier, file)

"""**For SVC:**"""

# Initialize the Support Vector Classifier model
from sklearn.svm import SVC
svc_classifier = SVC()

print(X_train)

# Train the Support Vector Classifier model on the training set
svc_classifier.fit(X_train, y_train)

# Make predictions on the testing set using the Support Vector Classifier model
y_pred_svc = svc_classifier.predict(X_test)

# Evaluate the Support Vector Classifier model
accuracy_svc = accuracy_score(y_test, y_pred_svc)
print("Support Vector Classifier Accuracy:", accuracy_svc)

# Print classification report for Support Vector Classifier
print("Support Vector Classifier Classification Report:")
print(classification_report(y_test, y_pred_svc))

joblib.dump(svc_classifier, 'SVC.joblib')

import numpy as np
import matplotlib.pyplot as plt
# from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from cuml.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train)
# Define a range of k values to try
k_values = range(1, 21)  # Try k from 1 to 20

# Initialize lists to store accuracy scores for different k values
accuracy_scores = []

# Iterate over each value of k
for k in k_values:
    # Initialize the KNN classifier with the current value of k
    knn_classifier = KNeighborsClassifier(n_neighbors=k)

    # Train the classifier on the training data
    knn_classifier.fit(X_train, y_train)

    # Make predictions on the testing data
    y_pred = knn_classifier.predict(X_test)

    # Calculate accuracy and append it to the list
    accuracy = accuracy_score(y_test, y_pred)
    accuracy_scores.append(accuracy)

# Plot the accuracy scores for different values of k
plt.figure(figsize=(10, 6))
plt.plot(k_values, accuracy_scores, marker='o', linestyle='-')
plt.title('Elbow Method for Choosing Optimal k')
plt.xlabel('Number of Neighbors (k)')
plt.ylabel('Accuracy')
plt.xticks(k_values)
plt.grid(True)
plt.show()

import pytz
from datetime import datetime

# timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
# print('timestamp in colab: ', timestamp)

# Set your local time zone
local_tz = pytz.timezone('Asia/Kolkata')

# Function to get the current timestamp in your local time zone
def get_local_timestamp():
    # Get the current timestamp in UTC
    utc_now = datetime.utcnow()

    # Convert to your local time zone
    local_now = utc_now.astimezone(local_tz)

    # Format the timestamp
    timestamp = local_now.strftime('%Y-%m-%d %H:%M:%S')
    return timestamp
localT = get_local_timestamp()
print("Local run time: ", localT)


# Find the index of maximum accuracy
max_accuracy_index = np.argmax(accuracy_scores)

# Extract the optimal value of k
optimal_k = k_values[max_accuracy_index]

# Extract the maximum accuracy
max_accuracy = accuracy_scores[max_accuracy_index]

print("Optimal k value:", optimal_k)
print("Maximum accuracy:", max_accuracy)

joblib.dump(knn_classifier, 'KNN.joblib')

!git clone https://github.com/rapidsai/rapidsai-csp-utils.git
!python rapidsai-csp-utils/colab/pip-install.py

from cuml.svm import SVC
import numpy as np

# Initialize the Support Vector Classifier model with different kernels
kernels = ['poly', 'rbf', 'sigmoid']
for kernel in kernels:
    print("Currently processing:",kernel)
    svc_classifier = SVC(kernel=kernel, cache_size=7000)

    # Convert X_train and X_test to NumPy arrays
    X_train_np = X_train.values.astype(np.float64)
    X_test_np = X_test.values.astype(np.float64)


    # Print the data type of the NumPy arrays
    print("Data type of X_train_np:", X_train_np.dtype)
    print("Data type of X_test_np:", X_test_np.dtype)

    # Train the Support Vector Classifier model on the training set
    svc_classifier.fit(X_train_np, y_train)

    # Make predictions on the testing set using the Support Vector Classifier model
    y_pred_svc = svc_classifier.predict(X_test_np)

    # Evaluate the Support Vector Classifier model
    accuracy_svc = accuracy_score(y_test, y_pred_svc)
    print("Support Vector Classifier Accuracy with", kernel, "kernel:", accuracy_svc)

    # Print classification report for Support Vector Classifier
    print("Support Vector Classifier Classification Report with", kernel, "kernel:")
    print(classification_report(y_test, y_pred_svc))
    print()

from sklearn.svm import LinearSVC
import numpy as np

# Initialize the Support Vector Classifier model with different kernels
kernels = ['linear']
for kernel in kernels:
    print("Currently processing:",kernel)
    linear_svc_classifier = LinearSVC()

    # Convert X_train and X_test to NumPy arrays
    X_train_np = X_train.values.astype(np.float64)
    X_test_np = X_test.values.astype(np.float64)


    # Print the data type of the NumPy arrays
    print("Data type of X_train_np:", X_train_np.dtype)
    print("Data type of X_test_np:", X_test_np.dtype)

    # Train the Support Vector Classifier model on the training set
    linear_svc_classifier.fit(X_train, y_train)

    # Make predictions on the testing set using the Support Vector Classifier model
    y_pred_svc = linear_svc_classifier.predict(X_test)

    # Evaluate the Support Vector Classifier model
    accuracy_svc = accuracy_score(y_test, y_pred_svc)
    print("Support Vector Classifier Accuracy with", kernel, "kernel:", accuracy_svc)

    # Print classification report for Support Vector Classifier
    print("Support Vector Classifier Classification Report with", kernel, "kernel:")
    print(classification_report(y_test, y_pred_svc))
    print()

import joblib
joblib.dump(linear_svc_classifier, 'SVC_Linear.joblib')

import xgboost as xgb
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the XGBoost Classifier
xgb_classifier = xgb.XGBClassifier()

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the XGBoost Classifier model on the training set
xgb_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the XGBoost Classifier model
y_pred_xgb = xgb_classifier.predict(X_test_np)

# Evaluate the XGBoost Classifier model
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
print("XGBoost Classifier Accuracy:", accuracy_xgb)

# Print classification report for XGBoost Classifier
print("XGBoost Classifier Classification Report:")
print(classification_report(y_test, y_pred_xgb))

import joblib
joblib.dump(xgb_classifier, 'XGB.joblib')

from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the base estimator (Decision Tree Classifier)
base_estimator = DecisionTreeClassifier(max_depth=1)

# Initialize the AdaBoost Classifier
ada_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=200)

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the AdaBoost Classifier model on the training set
ada_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the AdaBoost Classifier model
y_pred_ada = ada_classifier.predict(X_test_np)

# Evaluate the AdaBoost Classifier model
accuracy_ada = accuracy_score(y_test, y_pred_ada)
print("AdaBoost Classifier Accuracy:", accuracy_ada)

# Print classification report for AdaBoost Classifier
print("AdaBoost Classifier Classification Report:")
print(classification_report(y_test, y_pred_ada))

import joblib
joblib.dump(ada_classifier, 'ADAClassifier.joblib')

from sklearn.ensemble import GradientBoostingClassifier
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the Gradient Boosting Classifier
gbt_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the Gradient Boosting Classifier model on the training set
gbt_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the Gradient Boosting Classifier model
y_pred_gbt = gbt_classifier.predict(X_test_np)

# Evaluate the Gradient Boosting Classifier model
accuracy_gbt = accuracy_score(y_test, y_pred_gbt)
print("Gradient Boosting Classifier Accuracy:", accuracy_gbt)

# Print classification report for Gradient Boosting Classifier
print("Gradient Boosting Classifier Classification Report:")
print(classification_report(y_test, y_pred_gbt))

import joblib
joblib.dump(gbt_classifier, 'GBTClassifier.joblib')

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the base estimator (Decision Tree Classifier)
base_estimator = DecisionTreeClassifier()

# Initialize the Bagging Classifier
bagging_classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=100, random_state=42)

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the Bagging Classifier model on the training set
bagging_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the Bagging Classifier model
y_pred_bagging = bagging_classifier.predict(X_test_np)

# Evaluate the Bagging Classifier model
accuracy_bagging = accuracy_score(y_test, y_pred_bagging)
print("Bagging Classifier Accuracy:", accuracy_bagging)

# Print classification report for Bagging Classifier
print("Bagging Classifier Classification Report:")
print(classification_report(y_test, y_pred_bagging))

import joblib
joblib.dump(bagging_classifier, 'BaggingClassifier.joblib')

from sklearn.ensemble import StackingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the base estimators
estimators = [
    ('dt', DecisionTreeClassifier()),
    ('lr', LogisticRegression())
]

# Initialize the Stacking Classifier
stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the Stacking Classifier model on the training set
stacking_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the Stacking Classifier model
y_pred_stacking = stacking_classifier.predict(X_test_np)

# Evaluate the Stacking Classifier model
accuracy_stacking = accuracy_score(y_test, y_pred_stacking)
print("Stacking Classifier Accuracy:", accuracy_stacking)

# Print classification report for Stacking Classifier
print("Stacking Classifier Classification Report:")
print(classification_report(y_test, y_pred_stacking))
import joblib
joblib.dump(stacking_classifier, 'StackingClassifier.joblib')

from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the base estimators
estimators = [
    ('dt', DecisionTreeClassifier()),
    ('lr', LogisticRegression())
]

# Initialize the Voting Classifier
voting_classifier = VotingClassifier(estimators=estimators)

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the Voting Classifier model on the training set
voting_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the Voting Classifier model
y_pred_voting = voting_classifier.predict(X_test_np)

# Evaluate the Voting Classifier model
accuracy_voting = accuracy_score(y_test, y_pred_voting)
print("Voting Classifier Accuracy:", accuracy_voting)

# Print classification report for Voting Classifier
print("Voting Classifier Classification Report:")
print(classification_report(y_test, y_pred_voting))
joblib.dump(voting_classifier, 'VotingClassifier.joblib')

from sklearn.ensemble import ExtraTreesClassifier
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Initialize the ExtraTrees Classifier
extra_trees_classifier = ExtraTreesClassifier(n_estimators=100, random_state=42)

# Convert X_train and X_test to NumPy arrays with float32 data type
X_train_np = X_train.values.astype(np.float32)
X_test_np = X_test.values.astype(np.float32)

# Print the data type of the NumPy arrays
print("Data type of X_train_np:", X_train_np.dtype)
print("Data type of X_test_np:", X_test_np.dtype)

# Train the ExtraTrees Classifier model on the training set
extra_trees_classifier.fit(X_train_np, y_train)

# Make predictions on the testing set using the ExtraTrees Classifier model
y_pred_extra_trees = extra_trees_classifier.predict(X_test_np)

# Evaluate the ExtraTrees Classifier model
accuracy_extra_trees = accuracy_score(y_test, y_pred_extra_trees)
print("ExtraTrees Classifier Accuracy:", accuracy_extra_trees)

# Print classification report for ExtraTrees Classifier
print("ExtraTrees Classifier Classification Report:")
print(classification_report(y_test, y_pred_extra_trees))
joblib.dump(extra_trees_classifier, 'ExtraTreesClassifier.joblib')

"""**Conclusion:**


*   For the Random Forest, We get Accuracy: 0.9618288677157018
*   For the Support Vector Classifier, Accuracy: 0.6686877436119533
* For the KNN, we get Accuracy: 0.7477022279967278
* For Linear SVC, We get Accuracy: 0.8707473172609596

After Outlier Handling:


*   For the Random Forest, We get Accuracy:Accuracy: 0.9619363841971031
*   For the Support Vector Classifier, Accuracy: 0.6684471392137048
*   For the KNN, we get Accuracy: 0.7590106347144026   

**Note:** The remaining ensemble algorithms haven't been taken into consideration before performing outlier handling.

**Performance for the remaining algorithms:**

* XGBoost Classifier Accuracy: 0.9628025600307973
* Bagging Classifier Accuracy: 0.9625138347528993
* Stacking Classifier Accuracy: 0.9462489774313074
* Voting Classifier Accuracy: 0.8964919878735383
* ExtraTrees Classifier Accuracy: 0.9602521534093643



From this, we can infer that Random Forest Classifer fits the model well as we got the best accuracy and consistency among all these.


"""